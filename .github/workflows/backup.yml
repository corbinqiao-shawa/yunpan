name: è‡ªåŠ¨å¤‡ä»½Twitteråˆ°ç™¾åº¦ç½‘ç›˜
on:
  schedule:
    - cron: '0 0 * * *'  # æ¯å¤©å‡Œæ™¨0ç‚¹è‡ªåŠ¨è¿è¡Œï¼ˆåŒ—äº¬æ—¶é—´æ—©ä¸Š8ç‚¹ï¼‰
  workflow_dispatch:      # ä¹Ÿå¯ä»¥æ‰‹åŠ¨ç‚¹å‡»è¿è¡Œ

jobs:
  backup:
    runs-on: ubuntu-latest
    steps:
      - name: å‡†å¤‡å·¥ä½œç¯å¢ƒ
        uses: actions/checkout@v4
        
      - name: å®‰è£…Pythonå’Œå°å·¥å…·
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: å®‰è£…å¤‡ä»½éœ€è¦çš„é­”æ³•åº“
        run: |
          pip install --upgrade pip
          pip install ntscraper bypy
          
      - name: åˆ›å»ºå¤‡ä»½è„šæœ¬
        run: |
          echo "from ntscraper import Nitter; import json; import os; from datetime import datetime" > backup.py
          echo "scraper = Nitter()" >> backup.py
          echo "tweets = scraper.get_tweets('${{ secrets.TWITTER_USERNAME }}', mode='user', number=100)" >> backup.py
          echo "today = datetime.now().strftime('%Y-%m-%d')" >> backup.py
          echo "filename = f'twitter_backup_{today}.json'" >> backup.py
          echo "with open(filename, 'w', encoding='utf-8') as f:" >> backup.py
          echo "    json.dump(tweets, f, ensure_ascii=False, indent=2)" >> backup.py
          
      - name: è¿æ¥ç™¾åº¦ç½‘ç›˜å¹¶ä¸Šä¼ å¤‡ä»½
        run: |
         echo "${{ secrets.BAIDU_TOKEN }}" | bypy authorize
         bypy upload twitter_backup_*.json /twitter-backups/
          
      - name: æ˜¾ç¤ºå¤‡ä»½æˆåŠŸä¿¡æ¯
        run: echo "ğŸ‰ å¤‡ä»½å®Œæˆï¼æ–‡ä»¶å·²ç»å®‰å…¨å­˜åˆ°ç™¾åº¦ç½‘ç›˜å•¦ï¼"
        
