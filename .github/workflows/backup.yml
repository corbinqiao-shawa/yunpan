name: è‡ªåŠ¨å¤‡ä»½Twitteråˆ°ç™¾åº¦ç½‘ç›˜
on:
  schedule:
    - cron: '0 0 * * *'  # æ¯å¤©å‡Œæ™¨è‡ªåŠ¨å¤‡ä»½ï¼ˆåŒ—äº¬æ—¶é—´æ—©ä¸Š8ç‚¹ï¼‰
  workflow_dispatch:      # å¯ä»¥æ‰‹åŠ¨ç‚¹ä¸€ä¸‹å°±å¤‡ä»½

jobs:
  backup:
    runs-on: ubuntu-latest
    steps:
      - name: å‡†å¤‡å°æ¡Œå­
        uses: actions/checkout@v4
        
      - name: å®‰è£…é­”æ³•å·¥å…·
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: è£…æœ€æ–°çš„é­”æ³•ç›’å­
        run: |
          pip install --upgrade pip
          pip install --upgrade bypy ntscraper
          
      - name: å†™å¤‡ä»½å°è„šæœ¬
        run: |
          echo "from ntscraper import Nitter; import json; from datetime import datetime" > backup.py
          echo "scraper = Nitter(instance='https://nitter.net')" >> backup.py
          echo "try:" >> backup.py
          echo "    tweets = scraper.get_tweets('${{ secrets.TWITTER_USERNAME }}', mode='user', number=100)" >> backup.py
          echo "    today = datetime.now().strftime('%Y-%m-%d')" >> backup.py
          echo "    filename = f'twitter_backup_{today}.json'" >> backup.py
          echo "    with open(filename, 'w', encoding='utf-8') as f:" >> backup.py
          echo "        json.dump(tweets, f, ensure_ascii=False, indent=2)" >> backup.py
          echo "    print('âœ… æŠ“åˆ°Twitterå†…å®¹å•¦ï¼')" >> backup.py
          echo "except:" >> backup.py
          echo "    print('âš ï¸ æ²¡æŠ“åˆ°å†…å®¹ï¼Œè·³è¿‡ä¸Šä¼ ')" >> backup.py
          
      - name: è¿æ¥ç™¾åº¦ç½‘ç›˜
        run: |
          echo "${{ secrets.BAIDU_TOKEN }}" | bypy authorize
          bypy mkdir -p /twitter-backups/ || true
          if [ -f twitter_backup_*.json ]; then
            bypy upload twitter_backup_*.json /twitter-backups/
            echo "ğŸ‰ å¤‡ä»½æˆåŠŸï¼æ–‡ä»¶å·²ç»é£åˆ°ç™¾åº¦ç½‘ç›˜å•¦ï¼"
          else
            echo "âš ï¸ æ²¡æœ‰å¤‡ä»½æ–‡ä»¶ï¼Œä¸ç”¨ä¸Šä¼ "
          fi
